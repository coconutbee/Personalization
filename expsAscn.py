import argparse
import os
import json
import re
import torch
from tqdm import tqdm
from lmdeploy import pipeline, PytorchEngineConfig, GenerationConfig
from lmdeploy.vl import load_image

# ==========================================
# å·¥å…·å‡½å¼ï¼šæ™ºæ…§æœå°‹æª”æ¡ˆ (è§£æ±ºå¼•è™Ÿå•é¡Œ)
# ==========================================
def try_find_file(base_path, prompt_text, extensions):
    """
    å˜—è©¦å¤šç¨®è®Šé«”ä¾†å°‹æ‰¾æª”æ¡ˆï¼Œè§£æ±º ' å’Œ â€™ çš„å•é¡Œ
    """
    variants = [
        prompt_text,
        prompt_text.replace("'", "â€™"),  # è§£æ±º friend's -> friendâ€™s
        prompt_text.replace("'", "â€™").replace('"', 'â€') # åŒæ™‚è™•ç†å–®é›™å¼•è™Ÿ
    ]
    
    # å˜—è©¦å»é™¤æœ€å¾Œä¸€å€‹æ¨™é»ç¬¦è™Ÿ
    if prompt_text.endswith('.'):
        variants.append(prompt_text[:-1])

    for text in variants:
        for ext in extensions:
            filename = f"{text}{ext}"
            full_path = os.path.join(base_path, filename)
            
            if os.path.exists(full_path):
                return full_path, filename
    
    return None, None

# ==========================================
# å·¥å…·å‡½å¼ï¼šæå–åˆ†æ•¸
# ==========================================
def extract_score(text: str) -> float:
    """
    å¾ VLM å›è¦†ä¸­æå–åˆ†æ•¸ (æ”¯æ´ 0.9, 1.0, 1 ç­‰æ ¼å¼)
    è‹¥å¤±æ•—å›å‚³ -1.0
    """
    match = re.search(r"(?:Match )?Score[:\s\n*]+([0-9]+(?:\.[0-9]+)?)", text, re.IGNORECASE)
    if match:
        try:
            return float(match.group(1))
        except ValueError:
            return -1.0
    return -1.0

# ==========================================
# System Prompts
# ==========================================
# 1. è¡¨æƒ…åˆ†é¡ Prompt
EXPRESSION_PROMPT = """
Task: Classify the facial expression in the image into exactly one of the following categories.

Allowed Categories:
1. happy (e.g., smiling, laughing, joyful)
2. surprise (e.g., raised eyebrows, open mouth, shocked)
3. confuse (e.g., frowning, puzzled, unsure)
4. neutral (e.g., blank face, calm, no strong emotion)
5. sad (e.g., crying, frowning mouth corners, gloomy)
6. others (e.g., angry, disgusted, fearful, or if the expression is unclear)

Constraints:
- You must ONLY output one word from the list above.
- Do NOT output any punctuation.
- If the expression is ambiguous, choose 'others'.
"""

# 2. æƒ…å¢ƒåˆ†æ Prompt æ¨¡æ¿ (éœ€è¦å‹•æ…‹æ’å…¥ Input Text)
def get_scenario_prompt(input_text):
    return f"""
Task: Scenario Consistency Check

Input Text: "{input_text}"

You need to perform a two-step analysis:

Step 1: Text Extraction (Mental Process)
Analyze the Input Text and extract the **"Unique Situational Descriptor"**. 
- IGNORE: Gender (boy, girl), Standard Pose (turns head, looks up), and Basic Emotion labels (happy, sad).
- TARGET: The specific *cause* of the emotion, the *environmental element*, or the *subtle physical detail*.
- Examples:
  - "A girl faces downward with a shy smile, cheeks slightly blushing" -> Target: "cheeks slightly blushing"
  - "A boy looks upward... as snowflakes fall on his face" -> Target: "snowflakes fall on his face"

Step 2: Visual Verification
Look at the image. Does the visual content match the **"Unique Situational Descriptor"**?

Output Format:
- Extracted Context: ...
- Visual Evidence: ...
- Match Score: [0.0 to 1.0]

Constraints:
- 1.0: Specific scenario clearly visible.
- 0.5: General vibe matches, specific detail missing.
- 0.0: Scenario absent.
"""

# ==========================================
# ä¸»ç¨‹å¼
# ==========================================
def run_merged_eval(method, base_folder_path, json_path):
    # 1. æ¨¡å‹é…ç½®
    print("ğŸš€ æ­£åœ¨è¼‰å…¥ InternVL æ¨¡å‹...")
    backend_config = PytorchEngineConfig(tp=1, session_len=4096, cache_max_entry_count=0.2)
    pipe = pipeline('OpenGVLab/InternVL3_5-8B', backend_config=backend_config)
    
    # è¨­å®šç”Ÿæˆåƒæ•¸
    gen_config_expr = GenerationConfig(top_k=1, temperature=0.0) # è¡¨æƒ…éœ€è¦ç²¾æº–
    gen_config_scen = GenerationConfig(top_k=1, temperature=0.1) # æƒ…å¢ƒå…è¨±å¾®é‡å‰µæ„ä»¥è§£æèªæ„

    # 2. è®€å– JSON
    print(f"ğŸ“‚ æ­£åœ¨è®€å– JSON: {json_path}")
    if not os.path.exists(json_path):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {json_path}")
        return

    with open(json_path, 'r', encoding='utf-8') as f:
        data_list = json.load(f)

    print(f"ğŸ“Š ç¸½å…±éœ€è™•ç†: {len(data_list)} ç­†è³‡æ–™")

    # 3. æ‰¹æ¬¡æ¨è«–è¿´åœˆ
    batch_size = 4  # ä¾é¡¯å­˜èª¿æ•´ (å»ºè­° 4-8)
    valid_extensions = ['.png', '.jpg', '.jpeg', '.PNG'] 
    
    # çµ±è¨ˆç”¨
    expr_correct_count = 0
    expr_total_valid = 0
    total_scenario_score = 0.0
    scenario_count = 0

    for i in tqdm(range(0, len(data_list), batch_size), desc="VLM Evaluating"):
        batch_items = data_list[i : i + batch_size]
        
        # æº–å‚™å®¹å™¨
        expr_inputs = []   # è¡¨æƒ…æ¨è«–ç”¨ [(prompt, img), ...]
        scen_inputs = []   # æƒ…å¢ƒæ¨è«–ç”¨ [(prompt, img), ...]
        valid_indices = [] # ç´€éŒ„é€™æ‰¹è£¡é¢å“ªäº›æ˜¯æœ‰æ•ˆè®€å–åœ–ç‰‡çš„ (å°æ‡‰ batch_items çš„ index)

        for idx, item in enumerate(batch_items):
            prompt_text = item.get('prompt', '').strip()
            
            # --- A. æ‰¾åœ–ç‰‡ ---
            found_path, found_name = try_find_file(base_folder_path, prompt_text, valid_extensions)
            
            if not found_path:
                item['vlm_expression'] = "image_not_found"
                item['expression_correct'] = 0
                item['scenario_score'] = 0.0
                item['scenario_reasoning'] = "Image not found"
                continue

            try:
                # è¼‰å…¥åœ–ç‰‡ (lmdeploy æ ¼å¼)
                img = load_image(found_path)
                item['image'] = found_name # æ›´æ–°æ­£ç¢ºæª”å
                
                # --- B. æº–å‚™å…©å€‹ä»»å‹™çš„ Prompt ---
                # ä»»å‹™ 1: è¡¨æƒ…åˆ†é¡
                expr_inputs.append((EXPRESSION_PROMPT, img))
                
                # ä»»å‹™ 2: æƒ…å¢ƒåˆ†æ (å‹•æ…‹ç”Ÿæˆ Prompt)
                scen_prompt = get_scenario_prompt(prompt_text)
                scen_inputs.append((scen_prompt, img))
                
                valid_indices.append(idx)
                
            except Exception as e:
                print(f"\n[Error] è®€å–å¤±æ•—: {found_name} | {e}")
                continue

        if not valid_indices:
            continue

        try:
            # --- C. åŸ·è¡Œæ¨è«– (åˆ†å…©æ¬¡è·‘ï¼Œä½†æ¨¡å‹ä¸ç”¨é‡è¼‰) ---
            
            # 1. è·‘è¡¨æƒ…åˆ†é¡
            expr_responses = pipe(expr_inputs, gen_config=gen_config_expr)
            
            # 2. è·‘æƒ…å¢ƒåˆ†æ
            scen_responses = pipe(scen_inputs, gen_config=gen_config_scen)

            # --- D. è™•ç†çµæœä¸¦å¯«å› JSON ---
            for local_idx, resp_expr, resp_scen in zip(valid_indices, expr_responses, scen_responses):
                item = batch_items[local_idx]
                
                # [è™•ç†è¡¨æƒ…çµæœ]
                pred_expr = resp_expr.text.strip().lower().replace(".", "").replace("'", "")
                item['vlm_expression'] = pred_expr
                
                gt_expr = item.get('gt_expression', '').lower().strip()
                if gt_expr:
                    is_correct = (pred_expr == gt_expr)
                    item['expression_correct'] = 1 if is_correct else 0
                    expr_total_valid += 1
                    if is_correct: expr_correct_count += 1
                else:
                    item['expression_correct'] = None

                # [è™•ç†æƒ…å¢ƒçµæœ]
                scen_text = resp_scen.text
                score = extract_score(scen_text)
                
                item['scenario_reasoning'] = scen_text
                item['scenario_score'] = score
                
                if score >= 0:
                    total_scenario_score += score
                    scenario_count += 1

        except Exception as e:
            print(f"\n[Fatal Error] æ¨ç†ä¸­æ–·: {e}")
            break

    # 4. æœ€çµ‚å­˜æª”
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data_list, f, indent=4, ensure_ascii=False)
    
    print(f"\nâœ… å®Œæˆï¼çµæœå·²æ›´æ–°è‡³ {json_path}")
    
    # é¡¯ç¤ºçµ±è¨ˆæ•¸æ“š
    if expr_total_valid > 0:
        acc = (expr_correct_count / expr_total_valid) * 100
        print(f"ğŸ˜ è¡¨æƒ…æº–ç¢ºç‡: {acc:.2f}% ({expr_correct_count}/{expr_total_valid})")
    
    if scenario_count > 0:
        avg_scen = total_scenario_score / scenario_count
        print(f"ğŸ¬ å¹³å‡æƒ…å¢ƒåˆ†æ•¸: {avg_scen:.2f} (å…± {scenario_count} ç­†æœ‰æ•ˆè©•åˆ†)")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--method", type=str, default='pixart', help="folder selection")
    parser.add_argument("--json", type=str, required=True, help="Path to the JSON file")
    args = parser.parse_args()

    # è·¯å¾‘æ˜ å°„
    path_map = {
        'pixart': './pixart_outputs',
        'janus': './janus_outputs',
        'infinity': './infinity_outputs',
        'showo2': './showo2_outputs'
    }
    
    # é è¨­è·¯å¾‘ (å¦‚æœä¸åœ¨ map è£¡ï¼Œå¯è‡ªè¡Œä¿®æ”¹é è¨­å€¼æˆ–å ±éŒ¯)
    base_folder_path = path_map.get(args.method, './output')

    print(f"Method: {args.method}")
    print(f"Image Folder: {base_folder_path}")

    run_merged_eval(args.method, base_folder_path, args.json)
import argparse
import json
import os
import sys
import math
import numpy as np
import torch
import torchvision.transforms as transforms
from pathlib import Path
from PIL import Image
from scipy.spatial.transform import Rotation
from tqdm import tqdm

# ==========================================
# 0. ç’°å¢ƒè¨­å®š
# ==========================================
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# å˜—è©¦åŒ¯å…¥å°ˆæ¡ˆä¾è³´ (éœ€ç¢ºä¿ src è³‡æ–™å¤¾å­˜åœ¨)
try:
    from src.networks import get_EfficientNet_V2
    from src.fisher.fisher_utils import batch_torch_A_to_R
    HAS_REPO_UTILS = True
except ImportError:
    HAS_REPO_UTILS = False

# æª¢æŸ¥ MediaPipe
HAS_MEDIAPIPE = False
try:
    import mediapipe as mp
    # å¼·åˆ¶åŒ¯å…¥ solutions ä»¥æ”¯æ´ Python 3.12+ (å¦‚æœæœ‰çš„è©±)
    try:
        import mediapipe.python.solutions as mp_solutions
    except ImportError:
        mp_solutions = mp.solutions
    
    if hasattr(mp_solutions, 'pose'):
        HAS_MEDIAPIPE = True
except ImportError:
    pass

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# é—œéµé»ç´¢å¼•
IDX_L_SHOULDER = 11
IDX_R_SHOULDER = 12
FACE_LANDMARKS_INDICES = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

class SOTAConfig:
    def __init__(self):
        self.num_classes = 9 

# ==========================================
# å·¥å…·å‡½å¼: æ™ºæ…§æœå°‹åœ–ç‰‡
# ==========================================
def smart_find_image(base_folder, original_filename):
    """
    è‡ªå‹•å˜—è©¦å¤šç¨®æª”åçµ„åˆï¼Œç›´åˆ°æ‰¾åˆ°å­˜åœ¨çš„æª”æ¡ˆ
    å›å‚³: (full_path, found_filename) æˆ– (None, None)
    """
    if not original_filename:
        return None, None

    # å–å¾—æª”åèˆ‡å‰¯æª”å
    name_no_ext, ext = os.path.splitext(original_filename)
    
    # å®šç¾©æ‰€æœ‰å¯èƒ½çš„å€™é¸æª”å
    candidates = [
        f"0_{original_filename}",      # å˜—è©¦ 0_X.jpg
        original_filename,             # å˜—è©¦ X.jpg (åŸå§‹)
        f"0_{name_no_ext}.png",        # å˜—è©¦ 0_X.png
        f"{name_no_ext}.png"           # å˜—è©¦ X.png
    ]

    for cand in candidates:
        full_path = os.path.join(base_folder, cand)
        if os.path.exists(full_path):
            return full_path, cand
            
    return None, None

# ==========================================
# 1. æ ¸å¿ƒé‚è¼¯ (V-Final-Plus-Plus & Math)
# ==========================================
def normalize_angle(angle):
    if angle is None: return None
    angle = float(angle)
    while angle > 180: angle -= 360
    while angle < -180: angle += 360
    return angle

def limit_angle(angle):
    while angle < -180: angle += 360
    while angle > 180: angle -= 360
    return angle

def classify_pose_v_final(b_yaw, b_roll, h_yaw, h_pitch, h_roll, delta):
    """ V-Final-Plus-Plus åˆ†é¡é‚è¼¯ (ä¿ç•™åŸæ¨£) """
    abs_b_yaw = abs(b_yaw)
    abs_h_yaw = abs(h_yaw)
    
    # é–¾å€¼è¨­å®š
    if b_yaw > 0: THRES_BODY_SIDE_START = 35 
    else: THRES_BODY_SIDE_START = 20

    THRES_BODY_BACK = 89
    THRES_HEAD_FRONT_LIMIT = 30
    THRES_HEAD_PURE_TURN = 22 
    THRES_LEAN = 5 
    THRES_TILT = 8

    # Priority 1: æ—©æœŸå‚¾æ–œä¿è­·
    if abs_b_yaw < 40 and abs(b_roll) > THRES_LEAN:
        if b_roll > 0: return "Body_Lean_Right"
        else: return "Body_Lean_Left"

    # Priority 2: èƒŒå°é¡
    if abs_b_yaw > THRES_BODY_BACK:
        if abs(delta) < 40: return "Back_View_Straight"
        elif abs_h_yaw < 60: return "Back_Over_Shoulder"
        else: return "Back_View_Side_Looking_Away"

    # Priority 3: å¼·åˆ¶é ­è½‰
    if abs_h_yaw > 55 and abs_b_yaw < 60:
         return "Head_Turn_Right" if h_yaw > 0 else "Head_Turn_Left"

    # Priority 4: å´å‘å‹•ä½œçŸ©é™£
    is_body_side = (abs_b_yaw > THRES_BODY_SIDE_START) and (abs_b_yaw <= THRES_BODY_BACK)
    
    if is_body_side:
        final_yaw_direction_sign = 1 if b_yaw > 0 else -1
        if (b_yaw * h_yaw) < 0 and abs_h_yaw > 40:
            final_yaw_direction_sign = 1 if h_yaw > 0 else -1
        
        suffix = "Right" if final_yaw_direction_sign > 0 else "Left"
        is_head_side = abs_h_yaw > THRES_HEAD_FRONT_LIMIT
        
        if not is_head_side:
            return f"Body_Turn_{suffix}_Face_Front"
        else:
            corrected_b_yaw = abs_b_yaw * final_yaw_direction_sign
            if (corrected_b_yaw * h_yaw) > 0: 
                diff = abs_h_yaw - abs_b_yaw
                dominance_gap = 20 if h_yaw > 0 else 6
                if diff > dominance_gap: return f"Head_Turn_{suffix}"
                else: return f"Side_View_{suffix}"
            else: 
                return f"Head_Turn_{suffix}"

    # Priority 5: ç´”é ­è½‰
    if abs_h_yaw > THRES_HEAD_PURE_TURN:
        return "Head_Turn_Right" if h_yaw > 0 else "Head_Turn_Left"

    # Priority 6: æ®˜é¤˜æ­ªé ­é¡
    if h_roll > THRES_TILT: return "Head_Tilt_Left"
    if h_roll < -THRES_TILT: return "Head_Tilt_Right"

    # Priority 7: æ®˜é¤˜å‚¾æ–œé¡
    if b_roll > THRES_LEAN: return "Body_Lean_Right"
    if b_roll < -THRES_LEAN: return "Body_Lean_Left"

    # Priority 8: æ­£é¢é¡
    if h_yaw > 15: return "Head_Slight_Right"
    if h_yaw < -15: return "Head_Slight_Left"
    
    return "Frontal"

# ==========================================
# 2. æ¨¡å‹èˆ‡è¨ˆç®—å·¥å…·
# ==========================================
def load_model_correctly(checkpoint_path):
    print(f"ğŸ“‚ æ­£åœ¨è§£ææ¬Šé‡æª”: {checkpoint_path}")
    try:
        config = SOTAConfig()
        from src.networks import get_EfficientNet_V2
        model = get_EfficientNet_V2(config, model_name="S")
        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
        state_dict = checkpoint.get('model_state_dict_ema', checkpoint.get('model_state_dict', checkpoint))
        new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict, strict=True)
        model.to(DEVICE)
        model.eval()
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def compute_pose_output(output_tensor):
    if HAS_REPO_UTILS:
        with torch.no_grad():
            rot_mat = batch_torch_A_to_R(output_tensor).cpu().numpy()[0]
    else:
        A = output_tensor.view(-1, 3, 3)
        U, S, V = torch.linalg.svd(A)
        R = torch.matmul(U, V.transpose(1, 2))
        if torch.det(R) < 0:
            V_fixed = V.clone()
            V_fixed[:, :, 2] *= -1
            R = torch.matmul(U, V_fixed.transpose(1, 2))
        rot_mat = R.cpu().numpy()[0]
    rot_mat_2 = np.transpose(rot_mat)
    try:
        r = Rotation.from_matrix(rot_mat_2)
        angles = r.as_euler("xyz", degrees=True)
        return limit_angle(angles[1]), limit_angle(angles[0] - 180), limit_angle(angles[2])
    except:
        return 0.0, 0.0, 0.0

def get_face_box_from_pose(landmarks, w, h):
    x_coords = [landmarks[i].x * w for i in FACE_LANDMARKS_INDICES]
    y_coords = [landmarks[i].y * h for i in FACE_LANDMARKS_INDICES]
    if not x_coords: return None
    min_x, max_x = min(x_coords), max(x_coords)
    min_y, max_y = min(y_coords), max(y_coords)
    box_size = max(max_x - min_x, max_y - min_y) * 1.5
    cx, cy = (min_x + max_x) / 2, (min_y + max_y) / 2
    return [int(cx - box_size/2), int(cy - box_size/2), int(cx + box_size/2), int(cy + box_size/2)]

def calc_body_yaw(landmarks):
    l_sh = landmarks[IDX_L_SHOULDER]
    r_sh = landmarks[IDX_R_SHOULDER]
    if l_sh.visibility < 0.5 or r_sh.visibility < 0.5: return None
    dx, dz = r_sh.x - l_sh.x, r_sh.z - l_sh.z
    return -math.degrees(math.atan2(dz, dx)) * 2.0 

def calc_body_roll(landmarks, width, height):
    l_sh = landmarks[IDX_L_SHOULDER]
    r_sh = landmarks[IDX_R_SHOULDER]
    if l_sh.visibility < 0.5 or r_sh.visibility < 0.5: return 0.0
    lx, ly = l_sh.x * width, l_sh.y * height
    rx, ry = r_sh.x * width, r_sh.y * height
    return math.degrees(math.atan2(ly - ry, lx - rx))

# ==========================================
# 3. JSON è™•ç†ä¸»ç¨‹å¼
# ==========================================
def run_pose_labeling(method, image_dir, json_path, checkpoint_path):
    if not HAS_MEDIAPIPE:
        print("âŒ éŒ¯èª¤: æœªå®‰è£ MediaPipe (pip install mediapipe)")
        return

    print(f"Reading JSON from: {json_path}")
    print(f"Image Directory: {image_dir}")
    
    if not os.path.exists(json_path):
        print(f"Error: JSON file not found at {json_path}")
        return
    
    # æª¢æŸ¥è³‡æ–™å¤¾
    if not os.path.exists(image_dir):
        print(f"âš ï¸ Warning: Image folder not found at {image_dir}")
        
    # 1. åˆå§‹åŒ–æ¨¡å‹
    mp_pose = mp_solutions.pose
    pose_detector = mp_pose.Pose(static_image_mode=True, model_complexity=2, min_detection_confidence=0.5)
    head_model = load_model_correctly(checkpoint_path)
    if head_model is None: return

    # 2. è®€å–è³‡æ–™
    with open(json_path, 'r', encoding='utf-8') as f:
        data_list = json.load(f)

    print(f"Total items to process: {len(data_list)}")
    success_count = 0
    missing_count = 0
    
    # 3. è™•ç†è¿´åœˆ
    for item in tqdm(data_list, desc="Pose Predicting"):
        raw_filename = item.get("image", "").strip()
        
        # === [é—œéµä¿®æ”¹] ä½¿ç”¨æ™ºæ…§æœå°‹æ‰¾åˆ°æ­£ç¢ºè·¯å¾‘ ===
        full_image_path, found_name = smart_find_image(image_dir, raw_filename)
        
        prediction = "Image_Not_Found"
        
        if full_image_path:
            try:
                # åœ–ç‰‡è™•ç†
                img_pil = Image.open(full_image_path).convert("RGB")
                W, H = img_pil.size
                img_arr = np.array(img_pil)
                results = pose_detector.process(img_arr)
                
                raw_body_yaw = None
                raw_body_roll = 0.0
                h_yaw, h_pitch, h_roll = 0.0, 0.0, 0.0
                norm_body = None
                
                # è¨ˆç®—ç‰¹å¾µ
                if results.pose_landmarks:
                    lm = results.pose_landmarks.landmark
                    raw_body_yaw = calc_body_yaw(lm)
                    raw_body_roll = calc_body_roll(lm, W, H)
                    
                    bbox = get_face_box_from_pose(lm, W, H)
                    if bbox:
                        x1, y1, x2, y2 = bbox
                        crop = img_pil.crop((max(0, x1), max(0, y1), min(W, x2), min(H, y2)))
                        if crop.size[0] > 5 and crop.size[1] > 5:
                            tf = transforms.Compose([
                                transforms.Resize((224, 224)), transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                            ])
                            input_t = tf(crop).unsqueeze(0).to(DEVICE)
                            with torch.no_grad():
                                out = head_model(input_t)
                                h_yaw, h_pitch, h_roll = compute_pose_output(out)
                
                # æ­£è¦åŒ–èˆ‡é æ¸¬
                norm_body = normalize_angle(raw_body_yaw)
                norm_h_yaw = normalize_angle(h_yaw)
                
                delta = 0.0
                if norm_body is not None:
                    delta = abs(norm_h_yaw - norm_body)
                    if delta > 180: delta = 360 - delta
                
                if norm_body is None:
                    prediction = "No_Body_Detected"
                else:
                    prediction = classify_pose_v_final(norm_body, raw_body_roll, norm_h_yaw, h_pitch, h_roll, delta)
                
                success_count += 1
                
            except Exception as e:
                print(f"Error processing {raw_filename}: {e}")
                prediction = "Error"
        else:
            # çœŸçš„æ‰¾ä¸åˆ°åœ–
            missing_count += 1

        # 4. å¯«å…¥çµæœ
        item['pose_prediction'] = prediction
        
        # 5. è‡ªå‹•æ¯”å°æ­£ç¢ºæ€§
        gt_pose = item.get('gt_pose', '')
        if gt_pose and gt_pose != 'Unknown':
            # è½‰æˆ 0 æˆ– 1
            item['pose_correct'] = int(prediction == gt_pose)
        else:
            item['pose_correct'] = None

    # 6. å­˜æª”
    print(f"\nSaving updated JSON to: {json_path}")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data_list, f, indent=4, ensure_ascii=False)
    print(f"Success! Processed {success_count} images. Missing {missing_count} images.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--method", type=str, default='pixart')
    parser.add_argument("--json", type=str, default='output.json')
    parser.add_argument("--checkpoint", default='./pose/checkpoints/SemiUHPE/DAD-WildHead-EffNetV2-S-best.pth')
    args = parser.parse_args()

    # === [é—œéµä¿®æ”¹] æ›´æ–°è·¯å¾‘æ˜ å°„ (å°æ‡‰ faceswap_results) ===
    path_map = {
        'pixart': './faceswap_results/pixart',
        'janus': './faceswap_results/janus',
        'infinity': './faceswap_results/infinity',
        'showo2': './faceswap_results/showo2'
    }
    
    # é è¨­è·¯å¾‘
    image_dir = path_map.get(args.method, './output')

    run_pose_labeling(args.method, image_dir, args.json, args.checkpoint)